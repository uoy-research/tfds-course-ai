{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826740f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Matthew Care\"\n",
    "__version__ = \"0.0.3\"\n",
    "__date__ = \"2026-02-04\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71c8807",
   "metadata": {},
   "source": [
    "# Coding Exercise 2 (Simple) - Introduction to ML Pipelines and Hyperparameter Tuning\n",
    "\n",
    "## About This Version\n",
    "\n",
    "This is the **Simple** version of Coding Exercise 2, designed as an introduction to:\n",
    "- ML pipelines for preprocessing\n",
    "- Classification metrics for imbalanced data\n",
    "- Basic hyperparameter tuning with Optuna\n",
    "\n",
    "**To progress further**, see:\n",
    "- `02_ce2_adult_census_income_pipeline_advanced.py` for SMOTE resampling and threshold optimisation\n",
    "- `03_ce2_adult_census_income_pipeline_expert.py` for ensemble methods, calibration, and more\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will understand:\n",
    "1. How to build ML pipelines that prevent data leakage\n",
    "2. Why accuracy is misleading for imbalanced data\n",
    "3. How to use MCC (Matthews Correlation Coefficient) as a better metric\n",
    "4. How to tune a few key hyperparameters using Optuna\n",
    "\n",
    "## 0. Setup\n",
    "\n",
    "Key parameters you can modify:\n",
    "- `QUICK_MODE`: Set to `True` for faster runs\n",
    "- `TUNING_OBJECTIVE`: The metric to optimise (`\"mcc\"` or `\"f1\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c47481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.5\n",
    "QUICK_MODE = True\n",
    "\n",
    "N_SPLITS = 3 if QUICK_MODE else 5\n",
    "N_REPEATS_CV = 1 if QUICK_MODE else 2\n",
    "NUM_JOBS = -1\n",
    "\n",
    "out_folder = \"coding_exercise_2_simple\"\n",
    "out_suffix = \"_simple\"\n",
    "\n",
    "# Tuning configuration\n",
    "TUNING_OBJECTIVE = \"mcc\"  # Options: \"mcc\", \"f1\"\n",
    "N_TRIALS = 10 if QUICK_MODE else 30  # Number of Optuna trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f344c",
   "metadata": {},
   "source": [
    "### Understanding Imports\n",
    "\n",
    "Python uses `import` statements to load external libraries. Each library provides\n",
    "specialised functionality:\n",
    "\n",
    "- **pandas** (`pd`): Data manipulation with DataFrames (like Excel spreadsheets)\n",
    "- **numpy** (`np`): Numerical computing with arrays\n",
    "- **sklearn**: Machine learning algorithms and tools\n",
    "- **optuna**: Automated hyperparameter tuning\n",
    "- **lightgbm** (`lgb`): Fast gradient boosting library\n",
    "- **matplotlib/seaborn**: Plotting and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - load external libraries we need\n",
    "import sys  # System utilities (to check if we're in Google Colab)\n",
    "\n",
    "# Check if running in Google Colab (an online notebook environment)\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    import subprocess\n",
    "\n",
    "    packages = [\"optuna\", \"lightgbm\"]\n",
    "    for pkg in packages:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "import os  # Operating system utilities (for file paths)\n",
    "\n",
    "# Core data science libraries\n",
    "import lightgbm as lgb  # Fast gradient boosting (our ML model)\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import numpy as np  # Numerical arrays and math\n",
    "import optuna  # Hyperparameter tuning library\n",
    "import pandas as pd  # DataFrames for tabular data\n",
    "import seaborn as sns  # Statistical visualisation\n",
    "import sklearn  # Scikit-learn: the main ML library\n",
    "\n",
    "# TPESampler uses Bayesian optimisation to search hyperparameters efficiently\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Sklearn components - we import specific tools from sklearn's submodules\n",
    "# ColumnTransformer applies different preprocessing to different column types\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier  # Simple baseline model\n",
    "from sklearn.impute import SimpleImputer  # Fills in missing values\n",
    "\n",
    "# Metrics to evaluate model performance\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,  # Proportion of correct predictions\n",
    "    confusion_matrix,  # Table of prediction outcomes\n",
    "    f1_score,  # Balance of precision and recall\n",
    "    make_scorer,  # Converts a metric function into a scorer for CV\n",
    "    matthews_corrcoef,  # MCC - our primary metric for imbalanced data\n",
    "    precision_score,  # Of predicted positives, how many are correct\n",
    "    recall_score,  # Of actual positives, how many did we find\n",
    "    roc_auc_score,  # Area under ROC curve\n",
    ")\n",
    "\n",
    "# Model selection utilities\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline  # Chains preprocessing and model together\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder, RobustScaler\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_URL = \"https://github.com/medmaca/shared_data/raw/8a3fea5467ec68b17fd8369c6f77f8016b1ed5f8/Datasets/Kaggle/adult_census_income/adult.csv.zip\"\n",
    "\n",
    "adult_ci_df = pd.read_csv(\n",
    "    DATA_URL, compression=\"zip\"\n",
    ")  # The dataset is a CSV file inside a ZIP archive. Pandas can predict compression type but we specify it to be sure.\n",
    "adult_ci_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba3a42",
   "metadata": {},
   "source": [
    "## 1. Data Overview\n",
    "\n",
    "For full EDA, see Coding Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_ci_df.info()\n",
    "\n",
    "target_col = \"income\"\n",
    "class_props = adult_ci_df[target_col].value_counts(normalize=True)  # Proportion of each class in the target variable\n",
    "print(f\"\\nClass proportions:\\n{class_props}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c0819",
   "metadata": {},
   "source": [
    "### The Class Imbalance Problem\n",
    "\n",
    "The dataset has approximately 75% <=50K and 25% >50K. This is a **3:1 class imbalance**.\n",
    "\n",
    "**Why this matters:** A model that always predicts \"<=50K\" would achieve 75% accuracy,\n",
    "but would be completely useless for identifying high earners.\n",
    "\n",
    "**Solution:** Use metrics designed for imbalanced data, such as MCC or F1.\n",
    "\n",
    "For techniques to handle class imbalance (SMOTE resampling),\n",
    "see `02_ce2_adult_census_income_pipeline_advanced.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd0113",
   "metadata": {},
   "source": [
    "## 2. Key Classification Metrics\n",
    "\n",
    "### The Confusion Matrix\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc}\n",
    "& \\text{Pred. Neg} & \\text{Pred. Pos} \\\\\n",
    "\\hline\n",
    "\\text{Actual Neg} & TN & FP \\\\\n",
    "\\text{Actual Pos} & FN & TP \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "### Metrics Summary\n",
    "\n",
    "| Metric | Description | Use When |\n",
    "|--------|-------------|----------|\n",
    "| **Accuracy** | Overall correctness | Classes are balanced |\n",
    "| **MCC** | Correlation between prediction and truth | Imbalanced data (recommended) |\n",
    "| **F1** | Balance of precision and recall | Positive class is important |\n",
    "\n",
    "**MCC (Matthews Correlation Coefficient)** ranges from -1 to +1:\n",
    "- +1 = perfect prediction\n",
    "- 0 = random prediction\n",
    "- -1 = total disagreement\n",
    "\n",
    "For detailed metric explanations, see `02_ce2_adult_census_income_pipeline_advanced.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be5d5d",
   "metadata": {},
   "source": [
    "## 3. Prepare Data\n",
    "\n",
    "In this section, we'll separate our features (inputs) from the target (output)\n",
    "and split the data into training and test sets.\n",
    "\n",
    "### Python Concept: List Comprehensions\n",
    "\n",
    "The code below uses *list comprehensions* - a compact way to create lists by\n",
    "filtering or transforming another list. The syntax is:\n",
    "\n",
    "```python\n",
    "new_list = [item for item in old_list if condition]\n",
    "```\n",
    "\n",
    "This is equivalent to writing a `for` loop, but more concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b34591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values - replace \"?\" strings with proper NaN (Not a Number)\n",
    "adult_ci_df = adult_ci_df.replace(\"?\", np.nan)\n",
    "\n",
    "# List comprehension: get all columns except the target column\n",
    "# 'c for c in adult_ci_df.columns' iterates through each column name\n",
    "# 'if c != target_col' filters out the target\n",
    "feature_cols = [c for c in adult_ci_df.columns if c != target_col]\n",
    "\n",
    "# Separate categorical (text) and numeric columns by checking dtype\n",
    "# dtype == \"object\" means the column contains strings\n",
    "categorical_features = [c for c in feature_cols if adult_ci_df[c].dtype == \"object\"]\n",
    "numeric_features = [c for c in feature_cols if adult_ci_df[c].dtype != \"object\"]\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target - convert text labels (\"<=50K\", \">50K\") to numbers (0, 1)\n",
    "# LabelBinarizer learns the mapping and can transform in both directions\n",
    "lb = LabelBinarizer()\n",
    "# .fit_transform() learns the classes AND transforms in one step\n",
    "# .str.strip() removes leading/trailing whitespace from strings\n",
    "# .ravel() flattens the result to a 1D array\n",
    "adult_ci_df[\"target\"] = lb.fit_transform(adult_ci_df[target_col].str.strip()).ravel()\n",
    "print(\"Target classes:\", lb.classes_)  # Shows which class is 0 and which is 1\n",
    "\n",
    "# Create feature matrix X and target vector y\n",
    "# .copy() creates independent copies so changes don't affect the original\n",
    "X = adult_ci_df[feature_cols].copy()\n",
    "y = adult_ci_df[\"target\"].copy()\n",
    "\n",
    "# Train/test split - hold out some data to evaluate the final model\n",
    "# stratify=y ensures both sets have the same class proportions\n",
    "# random_state makes the split reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE)\n",
    "print(f\"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45fa23e",
   "metadata": {},
   "source": [
    "## 4. Build the Pipeline\n",
    "\n",
    "A **pipeline** chains preprocessing and modelling steps together. This:\n",
    "- Prevents data leakage (preprocessing is fitted only on training data)\n",
    "- Makes code cleaner and more reproducible\n",
    "- Ensures the same transformations are applied to new data\n",
    "\n",
    "### Python Concept: Functions\n",
    "\n",
    "A *function* is a reusable block of code. We define functions with `def`:\n",
    "\n",
    "```python\n",
    "def function_name(parameter1, parameter2):\n",
    "    \"\"\"Docstring explains what the function does.\"\"\"\n",
    "    # Function body - the code that runs when called\n",
    "    return result  # Return value (optional)\n",
    "```\n",
    "\n",
    "Functions help us avoid repeating code and make programs easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0db960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing steps - define how to handle each column type\n",
    "\n",
    "# Pipeline for numeric columns: impute missing values, then scale\n",
    "# Each step is a (name, transformer) tuple\n",
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # Fill NaN with median\n",
    "        (\"scaler\", RobustScaler()),  # Scale to similar ranges\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline for categorical columns: impute, then one-hot encode\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Fill NaN with mode\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),  # Convert to binary columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ColumnTransformer applies different pipelines to different column subsets\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", numeric_transformer, numeric_features),  # Apply to numeric cols\n",
    "        (\"cat\", categorical_transformer, categorical_features),  # Apply to categorical cols\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to build the complete pipeline\n",
    "def build_pipeline(estimator):\n",
    "    \"\"\"Build a complete preprocessing + model pipeline.\"\"\"\n",
    "    # Return a Pipeline that first preprocesses, then applies the model\n",
    "    return Pipeline(\n",
    "        [\n",
    "            (\"preprocess\", preprocessor),  # First step: preprocessing\n",
    "            (\"clf\", estimator),  # Second step: classifier (clf)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the pipeline structure\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf91df",
   "metadata": {},
   "source": [
    "## 5. Baseline Model\n",
    "\n",
    "Always compare against a baseline. A \"most frequent\" classifier simply predicts\n",
    "the majority class for all samples. If your tuned model can't beat this, something\n",
    "is wrong!\n",
    "\n",
    "**Why we need a baseline:** Without a reference point, we can't tell if our model\n",
    "has learned anything useful. A model with 75% accuracy might seem good, but if the\n",
    "baseline also achieves 75%, our model adds no value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e917e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: predict most frequent class (always predicts \"<=50K\")\n",
    "baseline = build_pipeline(DummyClassifier(strategy=\"most_frequent\"))\n",
    "baseline.fit(X_train, y_train)  # Train the baseline\n",
    "y_pred_baseline = baseline.predict(X_test)  # Make predictions on test set\n",
    "\n",
    "print(\"Baseline (predict majority class):\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"  MCC: {matthews_corrcoef(y_test, y_pred_baseline):.4f}\")  # Should be 0!\n",
    "print(f\"  F1: {f1_score(y_test, y_pred_baseline, zero_division=0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f883e",
   "metadata": {},
   "source": [
    "Note that the baseline achieves ~75% accuracy but MCC = 0 (random).\n",
    "This shows why accuracy is misleading for imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a55f25b",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning with Optuna\n",
    "\n",
    "**Hyperparameters** are settings we choose before training (e.g., number of trees).\n",
    "**Hyperparameter tuning** systematically searches for the best settings.\n",
    "\n",
    "### How Optuna Works\n",
    "\n",
    "Optuna uses *Bayesian optimisation* to efficiently search the parameter space.\n",
    "Instead of trying random combinations, it learns from previous trials to focus\n",
    "on promising regions.\n",
    "\n",
    "**Key concepts:**\n",
    "1. We define an **objective function** that Optuna calls repeatedly\n",
    "2. Each call is a **trial** with different hyperparameters\n",
    "3. Optuna provides a `trial` object with methods like `trial.suggest_int()` to propose parameter values\n",
    "4. Our function returns a score (higher is better when `direction=\"maximize\"`)\n",
    "5. Optuna learns which parameter regions give better scores\n",
    "\n",
    "We will tune **LightGBM** with just 3 key parameters:\n",
    "- `n_estimators`: Number of trees (more = more complex, slower)\n",
    "- `learning_rate`: Step size for updates (smaller = more stable, slower)\n",
    "- `max_depth`: Maximum tree depth (deeper = more complex)\n",
    "\n",
    "We also use `class_weight='balanced'` to help with class imbalance.\n",
    "\n",
    "For more comprehensive tuning with additional parameters and models,\n",
    "see `02_ce2_adult_census_income_pipeline_advanced.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the scorer - converts our metric into a function Optuna can use\n",
    "# make_scorer wraps a metric function so it can be used with cross-validation\n",
    "if TUNING_OBJECTIVE == \"mcc\":\n",
    "    tuning_scorer = make_scorer(matthews_corrcoef, greater_is_better=True)\n",
    "elif TUNING_OBJECTIVE == \"f1\":\n",
    "    tuning_scorer = make_scorer(f1_score, greater_is_better=True)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown objective: {TUNING_OBJECTIVE}\")\n",
    "\n",
    "\n",
    "# Define the objective function that Optuna will call for each trial\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function - returns CV score for a set of hyperparameters.\"\"\"\n",
    "    # trial.suggest_* methods ask Optuna to propose values for each parameter\n",
    "    # Optuna learns which combinations work well and focuses on those regions\n",
    "\n",
    "    # suggest_int(name, low, high) - proposes an integer in the range\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "\n",
    "    # suggest_float with log=True - samples on a log scale (good for learning rate)\n",
    "    # This means 0.01 and 0.1 are equally likely, not biased toward larger values\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True)\n",
    "\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "\n",
    "    # Create a LightGBM model with the suggested parameters\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        class_weight=\"balanced\",  # Automatically adjust weights for class imbalance\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1,  # Use 1 job per model (we parallelise at CV level)\n",
    "        verbose=-1,  # Suppress LightGBM output\n",
    "    )\n",
    "\n",
    "    # Build the complete pipeline with preprocessing\n",
    "    pipe = build_pipeline(model)\n",
    "\n",
    "    # Cross-validation: train and evaluate on different subsets of training data\n",
    "    # RepeatedStratifiedKFold: splits data into N_SPLITS folds, keeping class proportions\n",
    "    cv = RepeatedStratifiedKFold(n_splits=N_SPLITS, n_repeats=1, random_state=RANDOM_STATE)\n",
    "\n",
    "    # cross_val_score trains and evaluates the pipeline on each fold\n",
    "    # Returns an array of scores, one per fold\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=tuning_scorer, n_jobs=NUM_JOBS)\n",
    "\n",
    "    # Return the mean score - Optuna will try to maximise this\n",
    "    return float(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna optimization\n",
    "print(f\"Running Optuna with {N_TRIALS} trials...\")\n",
    "\n",
    "# Reduce Optuna's console output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Create an Optuna study to track optimization progress\n",
    "# direction=\"maximize\" because higher MCC/F1 is better\n",
    "# TPESampler uses Bayesian optimization (smarter than random search)\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(seed=RANDOM_STATE),  # For reproducibility\n",
    "    study_name=\"lightgbm_tuning\",\n",
    ")\n",
    "\n",
    "# Run the optimization - Optuna calls objective() N_TRIALS times\n",
    "# Each call tries different hyperparameters and returns a score\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "# study.best_value is the highest score achieved\n",
    "# study.best_params is a dictionary of the parameters that achieved it\n",
    "print(f\"\\nBest {TUNING_OBJECTIVE.upper()}: {study.best_value:.4f}\")\n",
    "print(f\"Best parameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3a024",
   "metadata": {},
   "source": [
    "## 7. Train Final Model\n",
    "\n",
    "During tuning, models were trained and discarded after scoring. Now we create\n",
    "a fresh model with the best parameters and train it on all training data.\n",
    "\n",
    "### Python Concept: Dictionary Access\n",
    "\n",
    "`study.best_params` is a *dictionary* mapping parameter names to values:\n",
    "```python\n",
    "{\"n_estimators\": 150, \"learning_rate\": 0.05, \"max_depth\": 10}\n",
    "```\n",
    "\n",
    "We access values with `dict[\"key\"]` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f742589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model using the best parameters found by Optuna\n",
    "# We access the best params from the study object\n",
    "best_model = lgb.LGBMClassifier(\n",
    "    n_estimators=study.best_params[\"n_estimators\"],  # Access dict value by key\n",
    "    learning_rate=study.best_params[\"learning_rate\"],\n",
    "    max_depth=study.best_params[\"max_depth\"],\n",
    "    class_weight=\"balanced\",  # Still use balanced weights\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=NUM_JOBS,  # Use NUM_JOBS cores for final training\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "# Build the complete pipeline and train on ALL training data\n",
    "best_pipeline = build_pipeline(best_model)\n",
    "best_pipeline.fit(X_train, y_train)  # Fit learns from data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a08e7a",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Test Set\n",
    "\n",
    "The test set has been held out completely during training and tuning.\n",
    "This gives us an unbiased estimate of how the model will perform on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a835b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred = best_pipeline.predict(X_test)  # Class predictions (0 or 1)\n",
    "y_test_proba = best_pipeline.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Print all metrics\n",
    "print(\"Final Model Performance:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  MCC: {matthews_corrcoef(y_test, y_test_pred):.4f}\")  # Compare to baseline MCC=0!\n",
    "print(f\"  F1: {f1_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"  ROC AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix - visualise prediction outcomes\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Compute confusion matrix from true and predicted labels\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Create a display object with proper class labels\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lb.classes_)\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")  # \"d\" formats as integers\n",
    "plt.gca().grid(False)  # Remove grid lines for cleaner look\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.tight_layout()  # Prevent labels from being cut off\n",
    "\n",
    "# Save to file and display\n",
    "plt.savefig(os.path.join(out_folder, f\"confusion_matrix{out_suffix}.pdf\"), dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f8a603",
   "metadata": {},
   "source": [
    "## 9. Interpreting Results\n",
    "\n",
    "Compare our tuned model to the baseline:\n",
    "\n",
    "| Metric | Baseline | Tuned LightGBM |\n",
    "|--------|----------|----------------|\n",
    "| Accuracy | ~75% | Check above |\n",
    "| MCC | 0 | Check above |\n",
    "\n",
    "The tuned model should have:\n",
    "- Similar or slightly lower accuracy (this is expected!)\n",
    "- Much higher MCC (actually useful predictions)\n",
    "- Reasonable precision and recall for both classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1cb7a6",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "1. **Pipelines** prevent data leakage and make code reproducible\n",
    "2. **MCC** is a better metric than accuracy for imbalanced data\n",
    "3. **Optuna** efficiently searches for good hyperparameters\n",
    "4. **class_weight='balanced'** helps models learn minority classes\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To continue learning, see:\n",
    "\n",
    "**Advanced version** (`02_ce2_adult_census_income_pipeline_advanced.py`):\n",
    "- SMOTE resampling for class imbalance\n",
    "- More models and hyperparameters\n",
    "- Threshold optimisation\n",
    "- More evaluation metrics\n",
    "\n",
    "**Expert version** (`03_ce2_adult_census_income_pipeline_expert.py`):\n",
    "- Ensemble methods (voting, stacking)\n",
    "- Probability calibration\n",
    "- Feature importance analysis\n",
    "- Learning curves\n",
    "- Cost-benefit analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3.14.2",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f24561",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Matthew Care\"\n",
    "__version__ = \"0.2.1\"\n",
    "__date__ = \"2026-01-26\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e98bfbf",
   "metadata": {},
   "source": [
    "# Coding Exercise 1 (Simple) - ML Introduction on the Adult Census Income Dataset\n",
    "\n",
    "This Colab-style notebook follows Episode 5 of the course.\n",
    "\n",
    "We will:\n",
    "- Frame the Adult Census Income prediction problem.\n",
    "- Load and explore an imbalanced tabular dataset.\n",
    "- Handle missing values and encode categorical variables.\n",
    "- Split data into stratified train/test sets.\n",
    "- Apply scaling to numerical features and one-hot encoding to categoricals.\n",
    "- Evaluate several scikit-learn models with **repeated stratified k-fold cross-validation** using **accuracy**.\n",
    "- Check for signs of overfitting.\n",
    "- Visualise accuracy distributions with violin plots.\n",
    "- Train the best model and evaluate it on a held-out test set with a confusion matrix.\n",
    "\n",
    "Note: This notebook deliberately uses **accuracy** on an **imbalanced** dataset. In Coding Exercise 2 we will revisit this with better metrics (precision, recall, F1, MCC, ROC/PR curves) and pipelines.\n",
    "\n",
    "**This is the Simple version.** For more advanced scaling options (e.g., QuantileTransformer for\n",
    "features with zero IQR) and additional EDA plots, see `02_ce1_adult_census_income_introduction_advanced.py`.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this exercise, you will understand:\n",
    "1. How to load and explore a tabular dataset with pandas\n",
    "2. How to handle missing values and encode categorical variables\n",
    "3. How to split data into train/test sets while preserving class proportions (stratification)\n",
    "4. How to scale numerical features and one-hot encode categorical features\n",
    "5. How to evaluate models using cross-validation\n",
    "6. How to detect overfitting by comparing train vs validation accuracy\n",
    "7. How to interpret a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afdd256",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "If you are running this in Google Colab, the next cell will ensure required libraries are installed. On most local setups with a recent Python and scikit-learn, these will already be available.\n",
    "\n",
    "### Understanding Imports\n",
    "\n",
    "Python uses `import` statements to load external libraries. Each library provides\n",
    "specialised functionality:\n",
    "\n",
    "- **numpy** (`np`): Numerical computing with arrays and mathematical operations\n",
    "- **pandas** (`pd`): Data manipulation with DataFrames (like Excel spreadsheets in Python)\n",
    "- **matplotlib.pyplot** (`plt`): Creating plots and visualisations\n",
    "- **seaborn** (`sns`): Statistical visualisation built on matplotlib\n",
    "- **sklearn**: Scikit-learn - the main machine learning library\n",
    "\n",
    "The `from X import Y` syntax imports specific functions or classes from a library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a5471",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# If running in Google Colab, install/upgrade key libraries (safe to run elsewhere).\n",
    "import sys  # System utilities - lets us check the Python environment\n",
    "\n",
    "# Check if we're running in Google Colab (an online notebook environment)\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    !pip -q install pandas numpy seaborn matplotlib scikit-learn\n",
    "    pass  # Packages are pre-installed in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec8806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports - load the libraries we'll use throughout this notebook\n",
    "import os  # Operating system utilities (for file paths)\n",
    "import warnings  # For controlling warning messages\n",
    "\n",
    "import matplotlib.pyplot as plt  # Plotting and visualisation\n",
    "import numpy as np  # Numerical computing - arrays and math\n",
    "import pandas as pd  # DataFrames - tabular data manipulation\n",
    "import seaborn as sns  # Statistical visualisation\n",
    "from sklearn.base import clone  # Create fresh copies of models\n",
    "\n",
    "# Suppress convergence warnings from models (e.g., LogisticRegression, SVC)\n",
    "# These can occur when features have zero variance after RobustScaler (IQR=0 features).\n",
    "# For a more sophisticated handling of such features, see the advanced version.\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*ConvergenceWarning.*\")\n",
    "from sklearn.dummy import DummyClassifier  # Baseline model\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "# Models: the classifiers we'll train and compare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics: measure model performance\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "\n",
    "# Sklearn imports - machine learning tools\n",
    "# train_test_split: splits data into training and test sets\n",
    "# RepeatedStratifiedKFold: cross-validation that preserves class proportions\n",
    "# cross_validate: runs cross-validation and returns multiple metrics\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Encoding utilities\n",
    "# Preprocessing: scale numbers and encode categories\n",
    "from sklearn.preprocessing import (\n",
    "    LabelBinarizer,  # Convert labels to 0/1\n",
    "    OneHotEncoder,  # Convert categories to binary columns\n",
    "    RobustScaler,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set visual style for all plots\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf7d77",
   "metadata": {},
   "source": [
    "### Configuration Guide\n",
    "\n",
    "Key parameters you can modify to experiment:\n",
    "\n",
    "- `RANDOM_STATE`: Seed for random number generation (ensures reproducibility)\n",
    "- `NUM_SPLITS`: Number of folds in cross-validation (typically 5 or 10)\n",
    "- `NUM_REPEATS`: How many times to repeat the CV process (more = more stable estimates)\n",
    "\n",
    "**Reproducibility:** Setting `RANDOM_STATE` ensures you get the same results each time\n",
    "you run the notebook. Try changing it to see how results vary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - these control the experiment\n",
    "RANDOM_STATE = 42  # Seed for reproducibility (42 is a common choice...)\n",
    "NUM_SPLITS = 5  # Number of CV folds\n",
    "NUM_REPEATS = 3  # Number of CV repeats (total evaluations = SPLITS × REPEATS)\n",
    "\n",
    "# Set random seed for numpy operations\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Create output folder for saving figures\n",
    "out_folder = \"coding_exercise_1_colab\"\n",
    "os.makedirs(out_folder, exist_ok=True)  # exist_ok=True prevents error if folder exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e121db7",
   "metadata": {},
   "source": [
    "## 2. Load the Adult Census Income Dataset\n",
    "\n",
    "We will use an **Adult Census Income** dataset, a classic imbalanced binary classification problem:\n",
    "\n",
    "- Each row is an individual.\n",
    "- Features describe demographics, work, and education.\n",
    "- Target: income level `<=50K` vs `>50K`.\n",
    "\n",
    "We load it directly from a zipped CSV hosted online.\n",
    "\n",
    "### Python Concept: DataFrames\n",
    "\n",
    "A *DataFrame* is pandas' core data structure - think of it as a spreadsheet or table:\n",
    "- Rows represent individual records (here, people)\n",
    "- Columns represent features/variables (age, education, etc.)\n",
    "- You access columns with `df[\"column_name\"]` or `df.column_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to zipped Adult Census Income CSV (single CSV inside the zip).\n",
    "DATA_URL = \"https://github.com/medmaca/shared_data/raw/8a3fea5467ec68b17fd8369c6f77f8016b1ed5f8/Datasets/Kaggle/adult_census_income/adult.csv.zip\"\n",
    "\n",
    "# pd.read_csv() reads a CSV file into a DataFrame\n",
    "# compression=\"zip\" tells pandas the file is compressed\n",
    "adult_ci_df = pd.read_csv(DATA_URL, compression=\"zip\")\n",
    "\n",
    "# .head() shows the first 5 rows - a quick preview of the data\n",
    "adult_ci_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b138fb",
   "metadata": {},
   "source": [
    "### Dataset overview\n",
    "\n",
    "Let's inspect basic structure: columns, dtypes, and target distribution.\n",
    "\n",
    "### Python Concept: Method Chaining\n",
    "\n",
    "Many pandas methods can be \"chained\" together:\n",
    "```python\n",
    "df[\"col\"].value_counts().sort_index()\n",
    "```\n",
    "This reads left-to-right: take column → count values → sort by index.\n",
    "Each method returns a new object that the next method operates on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .info() shows column names, data types, and non-null counts\n",
    "adult_ci_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a33905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .describe() computes summary statistics for all columns\n",
    "# include=\"all\" includes both numeric and categorical columns\n",
    "# .T transposes (flips rows/columns) for easier reading\n",
    "adult_ci_df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc875ad",
   "metadata": {},
   "source": [
    "### Target distribution (class imbalance)\n",
    "\n",
    "We check how many samples belong to each income class. This will show us whether the dataset is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which column contains the target (what we want to predict)\n",
    "target_col = \"income\"  # adjust if your column name differs\n",
    "\n",
    "# .value_counts() counts how many times each unique value appears\n",
    "# .sort_index() sorts alphabetically by the value (not by count)\n",
    "class_counts = adult_ci_df[target_col].value_counts().sort_index()\n",
    "\n",
    "# normalize=True gives proportions instead of raw counts (sums to 1.0)\n",
    "class_props = adult_ci_df[target_col].value_counts(normalize=True).sort_index()\n",
    "\n",
    "print(f\"Class counts:\\n{class_counts}\\n\")\n",
    "print(f\"Class proportions:\\n{class_props}\\n\")\n",
    "print(class_props)\n",
    "\n",
    "# Create a bar plot to visualise class imbalance\n",
    "plt.figure(figsize=(4, 4))  # Set figure size in inches (width, height)\n",
    "\n",
    "# sns.barplot creates a bar chart\n",
    "# x= specifies what goes on the x-axis (class labels)\n",
    "# y= specifies bar heights (counts)\n",
    "# hue= adds colour coding (here, same as x for distinct colours)\n",
    "# palette= chooses the colour scheme\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values, hue=class_counts.index, palette=\"viridis\", dodge=False)\n",
    "\n",
    "plt.title(\"Income class counts\")  # Add title\n",
    "plt.ylabel(\"Count\")  # Label y-axis\n",
    "plt.xlabel(\"Income class\")  # Label x-axis\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels 45 degrees\n",
    "plt.tight_layout()  # Adjust spacing to prevent labels being cut off\n",
    "\n",
    "# Save the figure to a file\n",
    "out_path = os.path.join(out_folder, \"income_class_counts.pdf\")  # Build file path\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")  # Save with high resolution\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8467ad9",
   "metadata": {},
   "source": [
    "We can already see **class imbalance**: one income class is noticeably more frequent than the other.\n",
    "\n",
    "In this Coding Exercise 1 we will still use **accuracy** as the performance metric, even though that's not ideal for imbalanced data. Coding Exercise 2 will address this in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4b95f",
   "metadata": {},
   "source": [
    "## 3. Handling Missing Data (`?`)\n",
    "\n",
    "In this dataset, missing values are encoded as the literal string `?` in several categorical columns.\n",
    "\n",
    "We will:\n",
    "- Count how many `?` appear per column.\n",
    "- Replace `?` with real missing values (`NaN`).\n",
    "- Impute missing values in categorical columns with the **most frequent** category.\n",
    "\n",
    "### Python Concept: Boolean Indexing\n",
    "\n",
    "When you compare a DataFrame to a value, Python creates a DataFrame of `True`/`False`:\n",
    "```python\n",
    "adult_ci_df == \"?\"  # Returns True where value equals \"?\", False elsewhere\n",
    "```\n",
    "Calling `.sum()` on booleans counts the `True` values (True=1, False=0).\n",
    "\n",
    "**Note:** In Coding Exercise 2, we'll use sklearn's `SimpleImputer` inside a Pipeline\n",
    "to handle missing values more elegantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f26136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values (\"?\") per column\n",
    "# == creates a boolean DataFrame (True where value is \"?\")\n",
    "# .sum() counts True values per column\n",
    "# .sort_values() sorts from lowest to highest count\n",
    "missing_counts = (adult_ci_df == \"?\").sum().sort_values(ascending=False)\n",
    "\n",
    "# Show only columns that have at least one missing value\n",
    "missing_counts[missing_counts > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834033f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with NaN so that pandas recognises them as missing\n",
    "# np.nan is pandas/numpy's representation of \"Not a Number\" (missing)\n",
    "adult_ci_df = adult_ci_df.replace(\"?\", np.nan)\n",
    "\n",
    "# --- Python Concept: List Comprehensions ---\n",
    "# A list comprehension creates a new list by filtering/transforming another:\n",
    "#   [item for item in collection if condition]\n",
    "# This is equivalent to a for loop, but more concise.\n",
    "\n",
    "# Get all column names except the target (these are our features)\n",
    "feature_cols = [c for c in adult_ci_df.columns if c != target_col]\n",
    "\n",
    "# Separate categorical (text) and numeric columns by checking data type\n",
    "# dtype == \"object\" means the column contains strings\n",
    "categorical_features = [c for c in feature_cols if adult_ci_df[c].dtype == \"object\"]\n",
    "numeric_features = [c for c in feature_cols if adult_ci_df[c].dtype != \"object\"]\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "\n",
    "# --- Python Concept: For Loops ---\n",
    "# A for loop repeats code for each item in a collection:\n",
    "#   for item in collection:\n",
    "#       # do something with item\n",
    "\n",
    "# Impute missing values in categorical columns with the mode (most frequent value)\n",
    "for col in categorical_features:\n",
    "    # .isna() returns True for missing values, .any() checks if any are True\n",
    "    if adult_ci_df[col].isna().any():\n",
    "        # .mode() returns the most frequent value(s); [0] takes the first\n",
    "        mode_val = adult_ci_df[col].mode(dropna=True)[0]\n",
    "        # .fillna() replaces NaN with the specified value\n",
    "        adult_ci_df[col] = adult_ci_df[col].fillna(mode_val)\n",
    "\n",
    "# Verify no NaNs remain in categorical columns\n",
    "adult_ci_df[categorical_features].isna().sum().sum(), \"total remaining NaNs in categoricals\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77c8f5",
   "metadata": {},
   "source": [
    "We chose **imputation** instead of dropping rows to preserve as much data as possible.\n",
    "\n",
    "Other strategies (like dropping rows/columns or model-based imputation) are possible,\n",
    "but the core idea is: make an explicit, documented choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908fafe",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "We now explore distributions of numerical features.\n",
    "\n",
    "**Note:** For additional EDA plots (correlation heatmaps, categorical countplots, stacked\n",
    "bar charts), see `02_ce1_adult_census_income_introduction_advanced.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398dd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of numeric features\n",
    "# This pattern creates a grid of subplots - one for each numeric feature\n",
    "\n",
    "n_num = len(numeric_features)  # Number of numeric features\n",
    "n_cols = 3  # We want 3 columns in our grid\n",
    "n_rows = int(np.ceil(n_num / n_cols))  # Calculate rows needed (ceiling division)\n",
    "\n",
    "# Create a figure with specified size (width × height in inches)\n",
    "plt.figure(figsize=(4 * n_cols, 3 * n_rows))\n",
    "\n",
    "# enumerate() gives us both index (i) and value (col) in the loop\n",
    "# start=1 makes i start at 1 instead of 0 (for subplot numbering)\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)  # Select the i-th subplot\n",
    "    # sns.histplot creates a histogram showing value distribution\n",
    "    sns.histplot(data=adult_ci_df, x=col, kde=False, bins=30, color=\"steelblue\")\n",
    "    plt.title(col)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "\n",
    "out_path = os.path.join(out_folder, \"numeric_feature_histograms.pdf\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb55643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots of numeric features stratified by income class (log10 y-scale)\n",
    "# Boxplots show the median, quartiles, and outliers for each group\n",
    "plt.figure(figsize=(4 * len(numeric_features), 4))\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    ax = plt.subplot(1, len(numeric_features), i)  # ax is the axes object\n",
    "    # sns.boxplot shows distribution split by x (income class)\n",
    "    sns.boxplot(data=adult_ci_df, x=target_col, y=col, ax=ax)\n",
    "    ax.set_yscale(\"log\", base=10)  # Use log scale for y-axis (handles skewed data)\n",
    "    ax.set_title(col)\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = os.path.join(out_folder, \"numeric_feature_boxplots.pdf\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e739f",
   "metadata": {},
   "source": [
    "These plots give us a sense of:\n",
    "- The range and skewness of numerical features.\n",
    "- How the income class relates to numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da54acb",
   "metadata": {},
   "source": [
    "## 5. Encode Target and Train/Test Split (Stratified)\n",
    "\n",
    "We now:\n",
    "- Encode the income target as 0/1.\n",
    "- Split into **50% train / 50% test**, stratified by class.\n",
    "- Use a fixed `random_state` for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target: convert text labels to numeric (0 and 1)\n",
    "# LabelBinarizer learns which class is 0 and which is 1\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# .fit_transform() learns the classes AND transforms in one step\n",
    "# .str.strip() removes leading/trailing whitespace from strings\n",
    "# .ravel() flattens the result to a 1D array (some sklearn functions need this)\n",
    "adult_ci_df[\"target\"] = lb.fit_transform(adult_ci_df[target_col].str.strip()).ravel()\n",
    "print(\"classes:\", lb.classes_)  # Shows which class is 0 and which is 1\n",
    "\n",
    "# Create feature matrix X and target vector y\n",
    "# Convention: X (capital) for features, y (lowercase) for target\n",
    "# .copy() creates independent copies so changes don't affect the original\n",
    "X = adult_ci_df[feature_cols].copy()\n",
    "y = adult_ci_df[\"target\"].copy()\n",
    "\n",
    "# Split data into training and test sets\n",
    "# test_size=0.5 means 50% for testing (large test set for reliable evaluation)\n",
    "# stratify=y ensures both sets have the same class proportions as the original\n",
    "# random_state makes the split reproducible (same split every time)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.5,\n",
    "    stratify=y,  # Preserve class balance in both sets\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n",
    "\n",
    "# Verify class proportions are preserved\n",
    "# .value_counts(normalize=True) gives proportions, .to_dict() converts to dictionary\n",
    "# List comprehension formats the output nicely\n",
    "print(f\"Train class distribution:{[f'{x} : {y:.3f}' for x, y in y_train.value_counts(normalize=True).to_dict().items()]}\")\n",
    "print(f\"Test class distribution:{[f'{x} : {y:.3f}' for x, y in y_test.value_counts(normalize=True).to_dict().items()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064bf209",
   "metadata": {},
   "source": [
    "## 6. Scaling Numerical Features with RobustScaler\n",
    "\n",
    "Our numeric features (e.g. `age`, `hours-per-week`, `capital-gain`, `capital-loss`) are often\n",
    "**skewed** with **outliers**.\n",
    "\n",
    "**[RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)**\n",
    "subtracts the median and divides by the IQR (interquartile range), making it more\n",
    "**robust to outliers** than StandardScaler.\n",
    "\n",
    "For features with IQR=0 (e.g., sparse features like `capital-gain` where most values are 0),\n",
    "RobustScaler leaves the values unchanged (no division by zero).\n",
    "\n",
    "**Note:** For alternative scaling strategies (e.g., QuantileTransformer for zero-IQR features),\n",
    "see `02_ce1_adult_census_income_introduction_advanced.py`.\n",
    "\n",
    "**Note:** In Coding Exercise 2, we'll use sklearn Pipelines to automate this preprocessing\n",
    "so it happens cleanly inside cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2541a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric columns from train and test sets\n",
    "X_train_num = X_train[numeric_features].copy()\n",
    "X_test_num = X_test[numeric_features].copy()\n",
    "\n",
    "# Create and fit RobustScaler on training data only\n",
    "# IMPORTANT: fit() learns parameters from TRAINING data only to prevent data leakage\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train_num)\n",
    "\n",
    "# Transform both train and test sets using the fitted scaler\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_train_num),\n",
    "    columns=numeric_features,\n",
    "    index=X_train.index,  # Preserve original row indices\n",
    ")\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_num),  # Use same scaler fitted on train\n",
    "    columns=numeric_features,\n",
    "    index=X_test.index,\n",
    ")\n",
    "\n",
    "X_train_num_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24347af2",
   "metadata": {},
   "source": [
    "## 7. Encoding Categorical Features (One-Hot / Dummy Variables)\n",
    "\n",
    "We one-hot encode categorical features.\n",
    "\n",
    "**One-hot encoding** converts a categorical column into multiple binary columns:\n",
    "- Original: `color = [red, blue, red, green]`\n",
    "- One-hot: `color_red=[1,0,1,0], color_blue=[0,1,0,0], color_green=[0,0,0,1]`\n",
    "\n",
    "To avoid **data leakage** from test to train, we:\n",
    "- Fit the encoder on the **training set** only.\n",
    "- Apply (transform) using the same encoder to both train and test.\n",
    "\n",
    "**Note:** In Coding Exercise 2, we'll use ColumnTransformer inside a Pipeline\n",
    "to handle this more elegantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn OneHotEncoder for categorical features\n",
    "X_train_cat = X_train[categorical_features].copy()\n",
    "X_test_cat = X_test[categorical_features].copy()\n",
    "\n",
    "# Create encoder instance\n",
    "# handle_unknown=\"ignore\" - if test set has categories not seen in training, encode as zeros\n",
    "# sparse_output=False - return a dense array instead of sparse matrix\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "# Fit on training data only - learns all unique categories\n",
    "ohe.fit(X_train_cat)\n",
    "\n",
    "# Transform both sets using the fitted encoder\n",
    "X_train_cat_encoded = ohe.transform(X_train_cat)\n",
    "X_test_cat_encoded = ohe.transform(X_test_cat)\n",
    "\n",
    "# Get the new column names (e.g., \"workclass_Private\", \"education_Bachelors\")\n",
    "ohe_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Convert numpy arrays back to DataFrames with proper column names and indices\n",
    "X_train_cat_dummies = pd.DataFrame(\n",
    "    X_train_cat_encoded,\n",
    "    columns=ohe_feature_names,\n",
    "    index=X_train.index,\n",
    ")\n",
    "X_test_cat_dummies = pd.DataFrame(\n",
    "    X_test_cat_encoded,\n",
    "    columns=ohe_feature_names,\n",
    "    index=X_test.index,\n",
    ")\n",
    "\n",
    "print(\"Train categorical dummy shape (OneHotEncoder):\", X_train_cat_dummies.shape)\n",
    "print(\"Test categorical dummy shape (OneHotEncoder):\", X_test_cat_dummies.shape)\n",
    "X_train_cat_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02835fe",
   "metadata": {},
   "source": [
    "### Combine processed numeric and categorical features\n",
    "\n",
    "We now concatenate the scaled numerical features with the one-hot encoded categorical\n",
    "features to form the final design matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the scaled numeric features\n",
    "X_train_num_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine scaled numeric features with one-hot encoded categorical features\n",
    "# pd.concat([df1, df2], axis=1) joins DataFrames side-by-side (column-wise)\n",
    "X_train_processed = pd.concat([X_train_num_scaled, X_train_cat_dummies], axis=1)\n",
    "X_test_processed = pd.concat([X_test_num_scaled, X_test_cat_dummies], axis=1)\n",
    "\n",
    "print(\"Processed train shape:\", X_train_processed.shape)\n",
    "print(\"Processed test shape:\", X_test_processed.shape)\n",
    "\n",
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dcd97d",
   "metadata": {},
   "source": [
    "**Note on leakage and pipelines**\n",
    "\n",
    "- We correctly avoided leakage between **train** and **test** by fitting scaling and\n",
    "  encoding only on the training data.\n",
    "- However, for cross-validation on `X_train_processed`, the preprocessing was fitted\n",
    "  once on the whole training set, not separately inside each CV fold.\n",
    "\n",
    "In Coding Exercise 2 we will use scikit-learn **Pipelines** so that preprocessing\n",
    "happens cleanly **inside** each cross-validation fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02893d0",
   "metadata": {},
   "source": [
    "## 8. Define a Model Zoo (5 Models)\n",
    "\n",
    "We set up a small collection of standard scikit-learn models:\n",
    "\n",
    "- [`DummyClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) (most frequent class baseline).\n",
    "- [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "- [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "- [`GradientBoostingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).\n",
    "- [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) (RBF kernel).\n",
    "\n",
    "The code is organised so you can easily add more models to this dictionary and have them\n",
    "automatically included in evaluation and visualisations. Look over\n",
    "https://scikit-learn.org/stable/supervised_learning.html and feel free to add additional\n",
    "models (note you'll have to import them before you can use them!)\n",
    "\n",
    "**Note:** we're setting hyperparameters manually in Coding Exercise 1, we'll explore\n",
    "hyperparameter tuning in Coding Exercise 2.\n",
    "\n",
    "### Python Concept: Dictionaries\n",
    "\n",
    "A *dictionary* maps keys to values:\n",
    "```python\n",
    "my_dict = {\"key1\": value1, \"key2\": value2}\n",
    "```\n",
    "- Access values with `my_dict[\"key1\"]`\n",
    "- Loop through with `for key, value in my_dict.items():`\n",
    "\n",
    "Here we use model names as keys and model instances as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d97daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of models to evaluate\n",
    "# Each key is a name (string), each value is a model instance\n",
    "models = {\n",
    "    \"DummyMostFreq\": DummyClassifier(strategy=\"most_frequent\"),  # Baseline: always predict majority class\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, n_jobs=-1),  # Linear model, n_jobs=-1 uses all CPU cores\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=200,  # Number of trees in the forest\n",
    "        max_depth=None,  # Trees grow until pure leaves\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),  # Sequential tree boosting\n",
    "    \"SVC\": SVC(kernel=\"rbf\", gamma=\"scale\", random_state=RANDOM_STATE),  # Support Vector Classifier with RBF kernel\n",
    "}\n",
    "\n",
    "# list() converts dictionary keys to a list for display\n",
    "list(models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c426cb5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 9. Repeated Stratified k-Fold Cross-Validation (Accuracy Only)\n",
    "\n",
    "We use **RepeatedStratifiedKFold** to get more stable estimates of accuracy:\n",
    "\n",
    "- For example: 5 folds × 3 repeats = 15 evaluations per model.\n",
    "- We record both **training** and **validation** accuracy per fold.\n",
    "- This lets us look for **overfitting** (very high train accuracy vs lower validation accuracy).\n",
    "\n",
    "### Python Concept: Functions\n",
    "\n",
    "A *function* is a reusable block of code. We define functions with `def`:\n",
    "\n",
    "```python\n",
    "def function_name(parameter1, parameter2):\n",
    "    \"\"\"Docstring explains what the function does.\"\"\"\n",
    "    # Function body - the code that runs when called\n",
    "    return result  # Return value (sent back to the caller)\n",
    "```\n",
    "\n",
    "Functions help us:\n",
    "- Avoid repeating code\n",
    "- Make programs easier to understand\n",
    "- Test pieces of code independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4183cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to evaluate one model with cross-validation\n",
    "def evaluate_model(X, y, model, model_name, cv):\n",
    "    \"\"\"Run cross-validation for a single model and return results as DataFrame.\"\"\"\n",
    "    # cross_validate runs CV and returns a dictionary of scores\n",
    "    cv_out = cross_validate(\n",
    "        model,  # The model to evaluate\n",
    "        X,  # Features\n",
    "        y,  # Target\n",
    "        cv=cv,  # Cross-validation splitter\n",
    "        scoring=\"accuracy\",  # Metric to compute\n",
    "        return_train_score=True,  # Also compute training scores (for overfitting check)\n",
    "        n_jobs=-1,  # Use all CPU cores for parallelisation\n",
    "    )\n",
    "    # Return results as a DataFrame\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"train_acc\": cv_out[\"train_score\"],  # Training accuracy per fold\n",
    "            \"val_acc\": cv_out[\"test_score\"],  # Validation accuracy per fold\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore:lbfgs failed to converge\"\n",
    "\n",
    "# Create the cross-validation splitter\n",
    "cv = RepeatedStratifiedKFold(\n",
    "    n_splits=NUM_SPLITS,  # Number of folds\n",
    "    n_repeats=NUM_REPEATS,  # Number of times to repeat\n",
    "    random_state=RANDOM_STATE,  # For reproducibility\n",
    ")\n",
    "\n",
    "# Evaluate all models and collect results\n",
    "all_results = []\n",
    "print(\"Starting model evaluations...\")\n",
    "\n",
    "# Loop through each model in our dictionary\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\t{model_name}\")  # Progress indicator\n",
    "    res = evaluate_model(X_train_processed, y_train, model, model_name, cv)\n",
    "    all_results.append(res)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "# pd.concat with ignore_index=True resets the row indices\n",
    "cv_results = pd.concat(all_results, ignore_index=True)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df99ca",
   "metadata": {},
   "source": [
    "### Mean train vs validation accuracy per model\n",
    "\n",
    "We summarise average training and validation accuracy to check for systematic overfitting.\n",
    "A large gap between train and validation accuracy suggests the model memorises training\n",
    "data rather than learning generalisable patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b176bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .groupby(\"model\") groups rows by model name\n",
    "# [[\"train_acc\", \"val_acc\"]] selects just these columns\n",
    "# .median() computes median for each group\n",
    "# .sort_values() sorts by validation accuracy (best model first)\n",
    "median_scores = cv_results.groupby(\"model\")[[\"train_acc\", \"val_acc\"]].median().sort_values(\"val_acc\", ascending=False)\n",
    "median_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84419102",
   "metadata": {},
   "source": [
    "If a model has **very high train accuracy** but noticeably lower validation accuracy,\n",
    "it may be **overfitting** (memorising training patterns that do not generalise).\n",
    "\n",
    "Models whose train and validation accuracies are closer together are typically better\n",
    "balanced between bias and variance for this setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ba017",
   "metadata": {},
   "source": [
    "## 10. Visualising Accuracy with Violin Plots\n",
    "\n",
    "We now visualise the distribution of **validation accuracy** across folds for each model\n",
    "using violin plots.\n",
    "\n",
    "This reveals not only the mean performance but also variability and potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd079a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create violin plot showing accuracy distribution for each model\n",
    "plt.figure(figsize=(8, 9))\n",
    "\n",
    "# sns.violinplot shows the distribution shape, not just summary statistics\n",
    "# inner=\"quartile\" draws lines at the quartiles inside the violin\n",
    "sns.violinplot(data=cv_results, x=\"model\", y=\"val_acc\", inner=\"quartile\", palette=\"Set2\")\n",
    "\n",
    "plt.title(\"Validation accuracy distribution by model (RepeatedStratifiedKFold)\")\n",
    "plt.ylabel(\"Validation accuracy\")\n",
    "\n",
    "# Add a horizontal reference line at the best model's median accuracy\n",
    "# .idxmax() returns the index (model name) with the maximum value\n",
    "plt.axhline(y=median_scores.loc[median_scores[\"val_acc\"].idxmax(), \"val_acc\"], color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylim(0.7, 1.0)  # Set y-axis range\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = os.path.join(out_folder, \"validation_accuracy_distribution_by_model.pdf\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d6380",
   "metadata": {},
   "source": [
    "Remember: **accuracy** can look quite good on an imbalanced dataset even if the minority\n",
    "class is poorly predicted.\n",
    "\n",
    "In Coding Exercise 2 we will revisit these models with more informative metrics\n",
    "(precision, recall, F1, MCC, ROC/PR curves)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe016a",
   "metadata": {},
   "source": [
    "## 11. Select the Best Model by Mean Validation Accuracy\n",
    "\n",
    "We now select the model with the highest **mean validation accuracy** across CV folds, then:\n",
    "\n",
    "- Fit that model on **all processed training data**.\n",
    "- Evaluate it once on the **held-out test set**.\n",
    "- Visualise the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best model by median validation accuracy\n",
    "# .idxmax() returns the row index (model name) with the highest value\n",
    "best_model_name = median_scores[\"val_acc\"].idxmax()\n",
    "best_model_name, median_scores.loc[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f539004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on FULL processed training data\n",
    "# clone() creates a fresh copy of the model (unfitted)\n",
    "best_model = clone(models[best_model_name])\n",
    "best_model.fit(X_train_processed, y_train)  # Train on all training data\n",
    "\n",
    "# Evaluate on held-out test set (data the model has never seen)\n",
    "y_test_pred = best_model.predict(X_test_processed)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test accuracy of best model ({best_model_name}): {test_acc:.4f}\")\n",
    "\n",
    "# Create and display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lb.classes_)\n",
    "disp.plot(cmap=\"Reds\", values_format=\"d\")  # \"d\" formats as integers\n",
    "\n",
    "ax = plt.gca()  # Get current axes\n",
    "ax.grid(False)  # Turn off grid for cleaner look\n",
    "\n",
    "plt.title(f\"Confusion matrix on held-out test set ({best_model_name})\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = os.path.join(out_folder, \"confusion_matrix_on_held_out_test_set.pdf\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2c0c9",
   "metadata": {},
   "source": [
    "The confusion matrix shows how many:\n",
    "- True negatives (correct `<=50K`)\n",
    "- True positives (correct `>50K`)\n",
    "- False positives (`<=50K` predicted as `>50K`)\n",
    "- False negatives (`>50K` predicted as `<=50K`)\n",
    "\n",
    "Even if overall accuracy looks good, we should be cautious if one type of error\n",
    "(e.g. false negatives) is particularly frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43204445",
   "metadata": {},
   "source": [
    "## 12. Wrap-Up and Bridge to Coding Exercise 2\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "- Framed the Adult Census Income prediction task as a **binary classification** problem.\n",
    "- Explored the data: feature types, distributions, class imbalance, and missing values.\n",
    "- Performed **stratified** train/test splitting with a fixed random seed.\n",
    "- Applied **RobustScaler** to numerical features and **one-hot encoding** to categorical\n",
    "  features using only the training data (to avoid leakage to test).\n",
    "- Evaluated several scikit-learn models using **RepeatedStratifiedKFold** and **accuracy**.\n",
    "- Checked for overfitting by comparing train vs validation accuracy.\n",
    "- Visualised accuracy distributions with violin plots.\n",
    "- Trained the best model on all training data and inspected its test-set confusion matrix.\n",
    "\n",
    "### Next steps (Coding Exercise 2)\n",
    "\n",
    "In Coding Exercise 2 and the accompanying notebook we will:\n",
    "\n",
    "- See why accuracy can be misleading on imbalanced data.\n",
    "- Introduce metrics like **precision**, **recall**, **F1**, **MCC**, **ROC/PR curves**.\n",
    "- Use **Pipelines** and **ColumnTransformer** to cleanly combine preprocessing and models.\n",
    "- Apply **hyperparameter tuning** (GridSearchCV, RandomizedSearchCV, Optuna) in a way\n",
    "  that respects cross-validation and avoids leakage.\n",
    "\n",
    "This will turn today's basic lifecycle into a more robust and production-ready ML workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3.14.2",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

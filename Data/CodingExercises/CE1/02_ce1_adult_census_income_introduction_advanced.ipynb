{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b518694",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Matthew Care\"\n",
    "__version__ = \"0.2.1\"\n",
    "__date__ = \"2026-01-26\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4581c0e2",
   "metadata": {},
   "source": [
    "# Coding Exercise 1 (Advanced) - ML Introduction on the Adult Census Income Dataset\n",
    "\n",
    "This Colab-style notebook follows Episode 5 of the course.\n",
    "\n",
    "We will:\n",
    "- Frame the Adult Census Income prediction problem.\n",
    "- Load and explore an imbalanced tabular dataset.\n",
    "- Handle missing values and encode categorical variables.\n",
    "- Split data into stratified train/test sets.\n",
    "- Apply scaling to numerical features and one-hot encoding to categoricals.\n",
    "- Evaluate several scikit-learn models with **repeated stratified k-fold cross-validation** using **accuracy**.\n",
    "- Check for signs of overfitting.\n",
    "- Visualise accuracy distributions with violin plots.\n",
    "- Train the best model and evaluate it on a held-out test set with a confusion matrix.\n",
    "\n",
    "Note: This notebook deliberately uses **accuracy** on an **imbalanced** dataset. In Coding Exercise 2 we will revisit this with better metrics (precision, recall, F1, MCC, ROC/PR curves) and pipelines.\n",
    "\n",
    "**This is the Advanced version** with additional EDA plots (correlation heatmaps, categorical\n",
    "countplots, stacked bar charts), more sophisticated scaling (QuantileTransformer for features\n",
    "with zero IQR), and a commented-out manual CV loop for educational reference.\n",
    "For a streamlined introduction, see `01_ce1_adult_census_income_introduction_simple.py`.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this exercise, you will understand:\n",
    "1. How to load and explore a tabular dataset with pandas\n",
    "2. How to handle missing values and encode categorical variables\n",
    "3. How to split data into train/test sets while preserving class proportions (stratification)\n",
    "4. How to scale numerical features and one-hot encode categorical features\n",
    "5. How to evaluate models using cross-validation\n",
    "6. How to detect overfitting by comparing train vs validation accuracy\n",
    "7. How to interpret a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586f471",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "If you are running this in Google Colab, the next cell will ensure required libraries are installed. On most local setups with a recent Python and scikit-learn, these will already be available.\n",
    "\n",
    "### Understanding Imports\n",
    "\n",
    "Python uses `import` statements to load external libraries. Each library provides\n",
    "specialised functionality:\n",
    "\n",
    "- **numpy** (`np`): Numerical computing with arrays and mathematical operations\n",
    "- **pandas** (`pd`): Data manipulation with DataFrames (like Excel spreadsheets in Python)\n",
    "- **matplotlib.pyplot** (`plt`): Creating plots and visualisations\n",
    "- **seaborn** (`sns`): Statistical visualisation built on matplotlib\n",
    "- **sklearn**: Scikit-learn - the main machine learning library\n",
    "\n",
    "The `from X import Y` syntax imports specific functions or classes from a library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2082a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# If running in Google Colab, install/upgrade key libraries (safe to run elsewhere).\n",
    "import sys  # System utilities - lets us check the Python environment\n",
    "\n",
    "# Check if we're running in Google Colab (an online notebook environment)\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    !pip -q install pandas numpy seaborn matplotlib scikit-learn\n",
    "    pass  # Packages are pre-installed in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports - load the libraries we'll use throughout this notebook\n",
    "import os  # Operating system utilities (for file paths)\n",
    "\n",
    "import matplotlib.pyplot as plt  # Plotting and visualisation\n",
    "import numpy as np  # Numerical computing - arrays and math\n",
    "import pandas as pd  # DataFrames - tabular data manipulation\n",
    "import seaborn as sns  # Statistical visualisation\n",
    "from sklearn.base import clone  # Create fresh copies of models\n",
    "from sklearn.dummy import DummyClassifier  # Baseline model\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "# Models: the classifiers we'll train and compare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics: measure model performance\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "\n",
    "# Sklearn imports - machine learning tools\n",
    "# train_test_split: splits data into training and test sets\n",
    "# RepeatedStratifiedKFold: cross-validation that preserves class proportions\n",
    "# cross_validate: runs cross-validation and returns multiple metrics\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Encoding utilities\n",
    "# Preprocessing: scale numbers and encode categories\n",
    "from sklearn.preprocessing import LabelBinarizer  # Convert labels to 0/1\n",
    "from sklearn.preprocessing import OneHotEncoder  # Convert categories to binary columns\n",
    "from sklearn.preprocessing import QuantileTransformer, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set visual style for all plots\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0774f",
   "metadata": {},
   "source": [
    "### Configuration Guide\n",
    "\n",
    "Key parameters you can modify to experiment:\n",
    "\n",
    "- `RANDOM_STATE`: Seed for random number generation (ensures reproducibility)\n",
    "- `NUM_SPLITS`: Number of folds in cross-validation (typically 5 or 10)\n",
    "- `NUM_REPEATS`: How many times to repeat the CV process (more = more stable estimates)\n",
    "\n",
    "**Reproducibility:** Setting `RANDOM_STATE` ensures you get the same results each time\n",
    "you run the notebook. Try changing it to see how results vary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0327262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - these control the experiment\n",
    "RANDOM_STATE = 42  # Seed for reproducibility (42 is a common choice...)\n",
    "NUM_SPLITS = 5  # Number of CV folds\n",
    "NUM_REPEATS = 3  # Number of CV repeats (total evaluations = SPLITS × REPEATS)\n",
    "\n",
    "# Set random seed for numpy operations\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Create output folder for saving figures\n",
    "out_folder = \"coding_exercise_1_colab\"\n",
    "os.makedirs(out_folder, exist_ok=True)  # exist_ok=True prevents error if folder exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad00fd7",
   "metadata": {},
   "source": [
    "## 2. Load the Adult Census Income Dataset\n",
    "\n",
    "We will use an **Adult Census Income** dataset, a classic imbalanced binary classification problem:\n",
    "\n",
    "- Each row is an individual.\n",
    "- Features describe demographics, work, and education.\n",
    "- Target: income level `<=50K` vs `>50K`.\n",
    "\n",
    "We load it directly from a zipped CSV hosted online.\n",
    "\n",
    "### Python Concept: DataFrames\n",
    "\n",
    "A *DataFrame* is pandas' core data structure - think of it as a spreadsheet or table:\n",
    "- Rows represent individual records (here, people)\n",
    "- Columns represent features/variables (age, education, etc.)\n",
    "- You access columns with `df[\"column_name\"]` or `df.column_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c00e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to zipped Adult Census Income CSV (single CSV inside the zip).\n",
    "DATA_URL = \"https://github.com/medmaca/shared_data/raw/8a3fea5467ec68b17fd8369c6f77f8016b1ed5f8/Datasets/Kaggle/adult_census_income/adult.csv.zip\"\n",
    "\n",
    "# pd.read_csv() reads a CSV file into a DataFrame\n",
    "# compression=\"zip\" tells pandas the file is compressed\n",
    "adult_ci_df = pd.read_csv(DATA_URL, compression=\"zip\")\n",
    "\n",
    "# .head() shows the first 5 rows - a quick preview of the data\n",
    "adult_ci_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95043dc1",
   "metadata": {},
   "source": [
    "### Dataset overview\n",
    "\n",
    "Let's inspect basic structure: columns, dtypes, and target distribution.\n",
    "\n",
    "### Python Concept: Method Chaining\n",
    "\n",
    "Many pandas methods can be \"chained\" together:\n",
    "```python\n",
    "df[\"col\"].value_counts().sort_index()\n",
    "```\n",
    "This reads left-to-right: take column → count values → sort by index.\n",
    "Each method returns a new object that the next method operates on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1856ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .info() shows column names, data types, and non-null counts\n",
    "adult_ci_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcd21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .describe() computes summary statistics for all columns\n",
    "# include=\"all\" includes both numeric and categorical columns\n",
    "# .T transposes (flips rows/columns) for easier reading\n",
    "adult_ci_df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f29d05",
   "metadata": {},
   "source": [
    "### Target distribution (class imbalance)\n",
    "\n",
    "We check how many samples belong to each income class. This will show us whether the dataset is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which column contains the target (what we want to predict)\n",
    "target_col = \"income\"  # adjust if your column name differs\n",
    "\n",
    "# .value_counts() counts how many times each unique value appears\n",
    "# .sort_index() sorts alphabetically by the value (not by count)\n",
    "class_counts = adult_ci_df[target_col].value_counts().sort_index()\n",
    "\n",
    "# normalize=True gives proportions instead of raw counts (sums to 1.0)\n",
    "class_props = adult_ci_df[target_col].value_counts(normalize=True).sort_index()\n",
    "\n",
    "print(f\"Class counts:\\n{class_counts}\\n\")\n",
    "print(f\"Class proportions:\\n{class_props}\\n\")\n",
    "print(class_props)\n",
    "\n",
    "# Create a bar plot to visualise class imbalance\n",
    "plt.figure(figsize=(4, 4))  # Set figure size in inches (width, height)\n",
    "\n",
    "# sns.barplot creates a bar chart\n",
    "# x= specifies what goes on the x-axis (class labels)\n",
    "# y= specifies bar heights (counts)\n",
    "# hue= adds colour coding (here, same as x for distinct colours)\n",
    "# palette= chooses the colour scheme\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values, hue=class_counts.index, palette=\"viridis\", dodge=False)\n",
    "\n",
    "plt.title(\"Income class counts\")  # Add title\n",
    "plt.ylabel(\"Count\")  # Label y-axis\n",
    "plt.xlabel(\"Income class\")  # Label x-axis\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels 45 degrees\n",
    "plt.tight_layout()  # Adjust spacing to prevent labels being cut off\n",
    "\n",
    "# Save the figure to a file\n",
    "out_path = os.path.join(out_folder, \"income_class_counts.pdf\")  # Build file path\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")  # Save with high resolution\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8994b8",
   "metadata": {},
   "source": [
    "We can already see **class imbalance**: one income class is noticeably more frequent than the other.\n",
    "\n",
    "In this Coding Exercise 1 we will still use **accuracy** as the performance metric, even though that's not ideal for imbalanced data. Coding Exercise 2 will address this in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16265160",
   "metadata": {},
   "source": [
    "## 3. Handling Missing Data (`?`)\n",
    "\n",
    "In this dataset, missing values are encoded as the literal string `?` in several categorical columns.\n",
    "\n",
    "We will:\n",
    "- Count how many `?` appear per column.\n",
    "- Replace `?` with real missing values (`NaN`).\n",
    "- Impute missing values in categorical columns with the **most frequent** category.\n",
    "\n",
    "### Python Concept: Boolean Indexing\n",
    "\n",
    "When you compare a DataFrame to a value, Python creates a DataFrame of `True`/`False`:\n",
    "```python\n",
    "adult_ci_df == \"?\"  # Returns True where value equals \"?\", False elsewhere\n",
    "```\n",
    "Calling `.sum()` on booleans counts the `True` values (True=1, False=0).\n",
    "\n",
    "**Note:** In Coding Exercise 2, we'll use sklearn's `SimpleImputer` inside a Pipeline\n",
    "to handle missing values more elegantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe60c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values (\"?\") per column\n",
    "# == creates a boolean DataFrame (True where value is \"?\")\n",
    "# .sum() counts True values per column\n",
    "# .sort_values() sorts from lowest to highest count\n",
    "missing_counts = (adult_ci_df == \"?\").sum().sort_values(ascending=False)\n",
    "\n",
    "# Show only columns that have at least one missing value\n",
    "missing_counts[missing_counts > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with NaN so that pandas recognises them as missing\n",
    "# np.nan is pandas/numpy's representation of \"Not a Number\" (missing)\n",
    "adult_ci_df = adult_ci_df.replace(\"?\", np.nan)\n",
    "\n",
    "# --- Python Concept: List Comprehensions ---\n",
    "# A list comprehension creates a new list by filtering/transforming another:\n",
    "#   [item for item in collection if condition]\n",
    "# This is equivalent to a for loop, but more concise.\n",
    "\n",
    "# Get all column names except the target (these are our features)\n",
    "feature_cols = [c for c in adult_ci_df.columns if c != target_col]\n",
    "\n",
    "# Separate categorical (text) and numeric columns by checking data type\n",
    "# dtype == \"object\" means the column contains strings\n",
    "categorical_features = [c for c in feature_cols if adult_ci_df[c].dtype == \"object\"]\n",
    "numeric_features = [c for c in feature_cols if adult_ci_df[c].dtype != \"object\"]\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "\n",
    "# --- Python Concept: For Loops ---\n",
    "# A for loop repeats code for each item in a collection:\n",
    "#   for item in collection:\n",
    "#       # do something with item\n",
    "\n",
    "# Impute missing values in categorical columns with the mode (most frequent value)\n",
    "for col in categorical_features:\n",
    "    # .isna() returns True for missing values, .any() checks if any are True\n",
    "    if adult_ci_df[col].isna().any():\n",
    "        # .mode() returns the most frequent value(s); [0] takes the first\n",
    "        mode_val = adult_ci_df[col].mode(dropna=True)[0]\n",
    "        # .fillna() replaces NaN with the specified value\n",
    "        adult_ci_df[col] = adult_ci_df[col].fillna(mode_val)\n",
    "\n",
    "# Verify no NaNs remain in categorical columns\n",
    "adult_ci_df[categorical_features].isna().sum().sum(), \"total remaining NaNs in categoricals\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061ea8f",
   "metadata": {},
   "source": [
    "We chose **imputation** instead of dropping rows to preserve as much data as possible.\n",
    "\n",
    "Other strategies (like dropping rows/columns or model-based imputation) are possible, but the core idea is: make an explicit, documented choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551aeef",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "We now explore:\n",
    "- Distributions of numerical features.\n",
    "- Relationships between some features and the income class.\n",
    "- Distributions of selected categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022365b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of numeric features\n",
    "# This pattern creates a grid of subplots - one for each numeric feature\n",
    "\n",
    "n_num = len(numeric_features)  # Number of numeric features\n",
    "n_cols = 3  # We want 3 columns in our grid\n",
    "n_rows = int(np.ceil(n_num / n_cols))  # Calculate rows needed (ceiling division)\n",
    "\n",
    "# Create a figure with specified size (width × height in inches)\n",
    "plt.figure(figsize=(4 * n_cols, 3 * n_rows))\n",
    "\n",
    "# enumerate() gives us both index (i) and value (col) in the loop\n",
    "# start=1 makes i start at 1 instead of 0 (for subplot numbering)\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)  # Select the i-th subplot\n",
    "    # sns.histplot creates a histogram showing value distribution\n",
    "    sns.histplot(data=adult_ci_df, x=col, kde=False, bins=30, color=\"steelblue\")\n",
    "    plt.title(col)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "\n",
    "out_path = os.path.join(out_folder, \"numeric_feature_histograms.pdf\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots of numeric features stratified by income class (log10 y-scale)\n",
    "# Boxplots show the median, quartiles, and outliers for each group\n",
    "plt.figure(figsize=(4 * len(numeric_features), 4))\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    ax = plt.subplot(1, len(numeric_features), i)  # ax is the axes object\n",
    "    # sns.boxplot shows distribution split by x (income class)\n",
    "    sns.boxplot(data=adult_ci_df, x=target_col, y=col, ax=ax)\n",
    "    ax.set_yscale(\"log\", base=10)  # Use log scale for y-axis (handles skewed data)\n",
    "    ax.set_title(col)\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = os.path.join(out_folder, \"numeric_feature_boxplots.pdf\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d1525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numeric features\n",
    "# Correlation measures how strongly two variables move together (-1 to +1)\n",
    "plt.figure(figsize=(6, 5))\n",
    "# .corr() computes pairwise correlations between all numeric columns\n",
    "corr = adult_ci_df[numeric_features].corr()\n",
    "# sns.heatmap visualises the correlation matrix with colours\n",
    "# annot=False hides numbers, cmap=\"bwr\" uses blue-white-red colours\n",
    "# center=0 makes white represent 0 correlation\n",
    "sns.heatmap(corr, annot=False, cmap=\"bwr\", center=0)\n",
    "plt.title(\"Correlation between numeric features\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = os.path.join(out_folder, \"numeric_feature_correlation_heatmap.pdf\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plots for a few key categorical features\n",
    "key_cats = [\"education\", \"workclass\", \"marital.status\", \"occupation\"]\n",
    "key_cats = [c for c in key_cats if c in categorical_features]\n",
    "\n",
    "for col in key_cats:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    order = adult_ci_df[col].value_counts().index\n",
    "    sns.countplot(data=adult_ci_df, x=col, order=order, hue=target_col)\n",
    "    plt.title(f\"{col} by income\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_path = os.path.join(out_folder, f\"categorical_countplot_{col}.pdf\")\n",
    "    plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "    print(f\"Saved figure to: {out_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f60b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised class percentages for key categorical features\n",
    "for col in key_cats:\n",
    "    # Crosstab of category vs income class, normalised by row to get percentages per category\\n\n",
    "    ct = pd.crosstab(adult_ci_df[col], adult_ci_df[target_col], normalize=\"index\") * 100.0\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ct.plot(kind=\"bar\", stacked=True, ax=plt.gca(), colormap=\"viridis\")\n",
    "    plt.title(f\"{col} by income (row-normalised %)\")\n",
    "    plt.ylabel(\"Percentage of samples in category\")\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.legend(title=target_col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_path = os.path.join(out_folder, f\"categorical_stacked_{col}.pdf\")\n",
    "    plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "    print(f\"Saved figure to: {out_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec8281",
   "metadata": {},
   "source": [
    "These plots give us a sense of:\n",
    "- The range and skewness of numerical features.\n",
    "- How some categorical features are distributed.\n",
    "- How the income class relates to features such as education or workclass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af49de",
   "metadata": {},
   "source": [
    "## 5. Encode Target and Train/Test Split (Stratified)\n",
    "\n",
    "We now:\n",
    "- Encode the income target as 0/1.\n",
    "- Split into **50% train / 50% test**, stratified by class.\n",
    "- Use a fixed `random_state` for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f37620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target: convert text labels to numeric (0 and 1)\n",
    "# LabelBinarizer learns which class is 0 and which is 1\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# .fit_transform() learns the classes AND transforms in one step\n",
    "# .str.strip() removes leading/trailing whitespace from strings\n",
    "# .ravel() flattens the result to a 1D array (some sklearn functions need this)\n",
    "adult_ci_df[\"target\"] = lb.fit_transform(adult_ci_df[target_col].str.strip()).ravel()\n",
    "print(\"classes:\", lb.classes_)  # Shows which class is 0 and which is 1\n",
    "\n",
    "# Create feature matrix X and target vector y\n",
    "# Convention: X (capital) for features, y (lowercase) for target\n",
    "# .copy() creates independent copies so changes don't affect the original\n",
    "X = adult_ci_df[feature_cols].copy()\n",
    "y = adult_ci_df[\"target\"].copy()\n",
    "\n",
    "# Split data into training and test sets\n",
    "# test_size=0.5 means 50% for testing (large test set for reliable evaluation)\n",
    "# stratify=y ensures both sets have the same class proportions as the original\n",
    "# random_state makes the split reproducible (same split every time)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.5,\n",
    "    stratify=y,  # Preserve class balance in both sets\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n",
    "\n",
    "# Verify class proportions are preserved\n",
    "# .value_counts(normalize=True) gives proportions, .to_dict() converts to dictionary\n",
    "# List comprehension formats the output nicely\n",
    "print(f\"Train class distribution:{[f'{x} : {y:.3f}' for x, y in y_train.value_counts(normalize=True).to_dict().items()]}\")\n",
    "print(f\"Test class distribution:{[f'{x} : {y:.3f}' for x, y in y_test.value_counts(normalize=True).to_dict().items()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669d50c",
   "metadata": {},
   "source": [
    "## 6. Scaling Numerical Features: RobustScaler vs StandardScaler\n",
    "\n",
    "Our numeric features (e.g. `age`, `hours-per-week`, `capital-gain`, `capital-loss`) are often **skewed** with **outliers**.\n",
    "\n",
    "- **[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)**: subtract mean, divide by standard deviation.\n",
    "  - Works well for roughly Gaussian data.\n",
    "  - **Sensitive to outliers**.\n",
    "- **[RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)**: subtract median, divide by IQR (interquartile range).\n",
    "  - More **robust to outliers** and heavy-tailed distributions.\n",
    "- **[QuantileScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html)**: This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme\n",
    "\n",
    "For this dataset we will use **RobustScaler** & **QuantileScaler** for numerical features.\n",
    "\n",
    "**Note:** In Coding Exercise 2, we'll use sklearn Pipelines to automate this preprocessing so it happens cleanly inside cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RobustScaler on training numeric features only for columns with non-zero IQR,\n",
    "# and use QuantileTransformer for numeric columns whose IQR is zero (e.g. highly sparse features).\n",
    "\n",
    "# Extract numeric columns from train and test sets\n",
    "X_train_num = X_train[numeric_features].copy()\n",
    "X_test_num = X_test[numeric_features].copy()\n",
    "\n",
    "# Compute IQR (Interquartile Range) on training data only\n",
    "# IQR = 75th percentile - 25th percentile\n",
    "q75 = X_train_num.quantile(0.75)  # 75th percentile for each column\n",
    "q25 = X_train_num.quantile(0.25)  # 25th percentile for each column\n",
    "iqr = q75 - q25\n",
    "\n",
    "# Some features have IQR=0 (e.g., capital-gain where most values are 0)\n",
    "# RobustScaler would divide by zero for these, so we use QuantileTransformer instead\n",
    "numeric_iqr_zero = iqr[iqr == 0].index.tolist()  # Columns with IQR=0\n",
    "numeric_iqr_nonzero = iqr[iqr != 0].index.tolist()  # Columns with IQR>0\n",
    "\n",
    "print(\"Numeric features with IQR == 0:\", numeric_iqr_zero)\n",
    "print(\"Numeric features with non-zero IQR:\", numeric_iqr_nonzero)\n",
    "\n",
    "# We'll collect scaled parts and concatenate them later\n",
    "scaled_train_parts = []\n",
    "scaled_test_parts = []\n",
    "\n",
    "# 1) RobustScaler for features with non-zero IQR\n",
    "if numeric_iqr_nonzero:\n",
    "    scaler = RobustScaler()  # Create scaler instance\n",
    "    X_train_nonzero = X_train_num[numeric_iqr_nonzero]\n",
    "    X_test_nonzero = X_test_num[numeric_iqr_nonzero]\n",
    "\n",
    "    # IMPORTANT: fit() learns parameters from TRAINING data only\n",
    "    # This prevents data leakage from test set\n",
    "    scaler.fit(X_train_nonzero)\n",
    "\n",
    "    # transform() applies the learned scaling to both sets\n",
    "    X_train_nonzero_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_train_nonzero),  # Apply scaling\n",
    "        columns=numeric_iqr_nonzero,\n",
    "        index=X_train.index,  # Preserve original row indices\n",
    "    )\n",
    "    X_test_nonzero_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test_nonzero),  # Use same scaler fitted on train\n",
    "        columns=numeric_iqr_nonzero,\n",
    "        index=X_test.index,\n",
    "    )\n",
    "    scaled_train_parts.append(X_train_nonzero_scaled)\n",
    "    scaled_test_parts.append(X_test_nonzero_scaled)\n",
    "\n",
    "# 2) QuantileTransformer for features with IQR == 0\n",
    "if numeric_iqr_zero:\n",
    "    qt = QuantileTransformer(\n",
    "        n_quantiles=min(1000, X_train_num.shape[0]),  # Number of quantiles to use\n",
    "        output_distribution=\"normal\",  # Transform to normal distribution\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    X_train_zero = X_train_num[numeric_iqr_zero]\n",
    "    X_test_zero = X_test_num[numeric_iqr_zero]\n",
    "\n",
    "    qt.fit(X_train_zero)  # Fit on training data only\n",
    "    X_train_zero_scaled = pd.DataFrame(\n",
    "        qt.transform(X_train_zero),\n",
    "        columns=numeric_iqr_zero,\n",
    "        index=X_train.index,\n",
    "    )\n",
    "    X_test_zero_scaled = pd.DataFrame(\n",
    "        qt.transform(X_test_zero),\n",
    "        columns=numeric_iqr_zero,\n",
    "        index=X_test.index,\n",
    "    )\n",
    "    scaled_train_parts.append(X_train_zero_scaled)\n",
    "    scaled_test_parts.append(X_test_zero_scaled)\n",
    "\n",
    "# Concatenate scaled parts and restore original numeric column order\n",
    "if scaled_train_parts:\n",
    "    # pd.concat joins DataFrames along columns (axis=1)\n",
    "    X_train_num_scaled = pd.concat(scaled_train_parts, axis=1)\n",
    "    X_test_num_scaled = pd.concat(scaled_test_parts, axis=1)\n",
    "    # Reorder columns to match original order\n",
    "    X_train_num_scaled = X_train_num_scaled[numeric_features]\n",
    "    X_test_num_scaled = X_test_num_scaled[numeric_features]\n",
    "else:\n",
    "    # Fallback: no numeric features (unlikely in this dataset)\n",
    "    X_train_num_scaled = X_train_num.copy()\n",
    "    X_test_num_scaled = X_test_num.copy()\n",
    "\n",
    "X_train_num_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d982d7a2",
   "metadata": {},
   "source": [
    "## 7. Encoding Categorical Features (One-Hot / Dummy Variables)\n",
    "\n",
    "We one-hot encode categorical features.\n",
    "\n",
    "**One-hot encoding** converts a categorical column into multiple binary columns:\n",
    "- Original: `color = [red, blue, red, green]`\n",
    "- One-hot: `color_red=[1,0,1,0], color_blue=[0,1,0,0], color_green=[0,0,0,1]`\n",
    "\n",
    "To avoid **data leakage** from test to train, we:\n",
    "- Fit the encoder on the **training set** only.\n",
    "- Apply (transform) using the same encoder to both train and test.\n",
    "\n",
    "**Note:** In Coding Exercise 2, we'll use ColumnTransformer inside a Pipeline to handle this more elegantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn OneHotEncoder for categorical features\n",
    "X_train_cat = X_train[categorical_features].copy()\n",
    "X_test_cat = X_test[categorical_features].copy()\n",
    "\n",
    "# Create encoder instance\n",
    "# handle_unknown=\"ignore\" - if test set has categories not seen in training, encode as zeros\n",
    "# sparse_output=False - return a dense array instead of sparse matrix\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "# Fit on training data only - learns all unique categories\n",
    "ohe.fit(X_train_cat)\n",
    "\n",
    "# Transform both sets using the fitted encoder\n",
    "X_train_cat_encoded = ohe.transform(X_train_cat)\n",
    "X_test_cat_encoded = ohe.transform(X_test_cat)\n",
    "\n",
    "# Get the new column names (e.g., \"workclass_Private\", \"education_Bachelors\")\n",
    "ohe_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Convert numpy arrays back to DataFrames with proper column names and indices\n",
    "X_train_cat_dummies = pd.DataFrame(\n",
    "    X_train_cat_encoded,\n",
    "    columns=ohe_feature_names,\n",
    "    index=X_train.index,\n",
    ")\n",
    "X_test_cat_dummies = pd.DataFrame(\n",
    "    X_test_cat_encoded,\n",
    "    columns=ohe_feature_names,\n",
    "    index=X_test.index,\n",
    ")\n",
    "\n",
    "print(\"Train categorical dummy shape (OneHotEncoder):\", X_train_cat_dummies.shape)\n",
    "print(\"Test categorical dummy shape (OneHotEncoder):\", X_test_cat_dummies.shape)\n",
    "X_train_cat_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921551d4",
   "metadata": {},
   "source": [
    "### Combine processed numeric and categorical features\n",
    "\n",
    "We now concatenate the scaled numerical features with the one-hot encoded categorical features to form the final design matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c079cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the scaled numeric features\n",
    "X_train_num_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b08ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine scaled numeric features with one-hot encoded categorical features\n",
    "# pd.concat([df1, df2], axis=1) joins DataFrames side-by-side (column-wise)\n",
    "X_train_processed = pd.concat([X_train_num_scaled, X_train_cat_dummies], axis=1)\n",
    "X_test_processed = pd.concat([X_test_num_scaled, X_test_cat_dummies], axis=1)\n",
    "\n",
    "print(\"Processed train shape:\", X_train_processed.shape)\n",
    "print(\"Processed test shape:\", X_test_processed.shape)\n",
    "\n",
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c25aaf",
   "metadata": {},
   "source": [
    "**Note on leakage and pipelines**\n",
    "\n",
    "- We correctly avoided leakage between **train** and **test** by fitting scaling and encoding only on the training data.\n",
    "- However, for cross-validation on `X_train_processed`, the preprocessing was fitted once on the whole training set, not separately inside each CV fold.\n",
    "\n",
    "In Coding Exercise 2 we will use scikit-learn **Pipelines** so that preprocessing happens cleanly **inside** each cross-validation fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792ca27",
   "metadata": {},
   "source": [
    "## 8. Define a Model Zoo (5 Models)\n",
    "\n",
    "We set up a small collection of standard scikit-learn models:\n",
    "\n",
    "- [`DummyClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) (most frequent class baseline).\n",
    "- [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "- [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "- [`GradientBoostingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).\n",
    "- [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) (RBF kernel).\n",
    "\n",
    "The code is organised so you can easily add more models to this dictionary and have them automatically included in evaluation and visualisations.  Look over https://scikit-learn.org/stable/supervised_learning.html and feel free to add additional models (note you'll have to import them before you can use them!)\n",
    "\n",
    "**Note:** we're setting hyperparameters manually in Coding Exercise 1, we'll explore hyperparameter tuning in Coding Exercise 2.\n",
    "\n",
    "### Python Concept: Dictionaries\n",
    "\n",
    "A *dictionary* maps keys to values:\n",
    "```python\n",
    "my_dict = {\"key1\": value1, \"key2\": value2}\n",
    "```\n",
    "- Access values with `my_dict[\"key1\"]`\n",
    "- Loop through with `for key, value in my_dict.items():`\n",
    "\n",
    "Here we use model names as keys and model instances as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61157e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of models to evaluate\n",
    "# Each key is a name (string), each value is a model instance\n",
    "models = {\n",
    "    \"DummyMostFreq\": DummyClassifier(strategy=\"most_frequent\"),  # Baseline: always predict majority class\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, n_jobs=-1),  # Linear model, n_jobs=-1 uses all CPU cores\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=200,  # Number of trees in the forest\n",
    "        max_depth=None,  # Trees grow until pure leaves\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),  # Sequential tree boosting\n",
    "    \"SVC\": SVC(kernel=\"rbf\", gamma=\"scale\", random_state=RANDOM_STATE),  # Support Vector Classifier with RBF kernel\n",
    "}\n",
    "\n",
    "# list() converts dictionary keys to a list for display\n",
    "list(models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ad740",
   "metadata": {},
   "source": [
    "## 9. Repeated Stratified k-Fold Cross-Validation (Accuracy Only)\n",
    "\n",
    "We use **RepeatedStratifiedKFold** to get more stable estimates of accuracy:\n",
    "\n",
    "- For example: 5 folds × 3 repeats = 15 evaluations per model.\n",
    "- We record both **training** and **validation** accuracy per fold.\n",
    "- This lets us look for **overfitting** (very high train accuracy vs lower validation accuracy).\n",
    "\n",
    "### Python Concept: Functions\n",
    "\n",
    "A *function* is a reusable block of code. We define functions with `def`:\n",
    "\n",
    "```python\n",
    "def function_name(parameter1, parameter2):\n",
    "    \"\"\"Docstring explains what the function does.\"\"\"\n",
    "    # Function body - the code that runs when called\n",
    "    return result  # Return value (sent back to the caller)\n",
    "```\n",
    "\n",
    "Functions help us:\n",
    "- Avoid repeating code\n",
    "- Make programs easier to understand\n",
    "- Test pieces of code independently\n",
    "\n",
    "### About the Code Below\n",
    "\n",
    "The commented-out code shows the **manual approach** to cross-validation - explicitly\n",
    "looping through folds and training models. This is kept for educational purposes so\n",
    "you can see what's happening \"under the hood\".\n",
    "\n",
    "The active code uses sklearn's `cross_validate()` function, which does the same thing\n",
    "but more concisely and with automatic parallelisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MANUAL CV LOOP (commented out - kept for reference)\n",
    "# ============================================================================\n",
    "# This shows what cross_validate() does internally:\n",
    "# 1. Split data into folds\n",
    "# 2. For each fold: train on N-1 folds, validate on 1 fold\n",
    "# 3. Record scores\n",
    "#\n",
    "# rskf = RepeatedStratifiedKFold(\n",
    "#     n_splits=NUM_SPLITS,\n",
    "#     n_repeats=NUM_REPEATS,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "#\n",
    "# records = []\n",
    "# X_arr = X_train_processed.values  # Convert DataFrame to numpy array\n",
    "# y_arr = y_train.values\n",
    "#\n",
    "# # rskf.split() yields train/val indices for each fold\n",
    "# for fold_idx, (train_idx, val_idx) in enumerate(rskf.split(X_arr, y_arr), start=1):\n",
    "#     X_tr, X_val = X_arr[train_idx], X_arr[val_idx]  # Split features\n",
    "#     y_tr, y_val = y_arr[train_idx], y_arr[val_idx]  # Split targets\n",
    "#\n",
    "#     for model_name, model in models.items():\n",
    "#         clf = clone(model)  # Create fresh copy (models are stateful after fitting)\n",
    "#         clf.fit(X_tr, y_tr)  # Train on this fold's training data\n",
    "#\n",
    "#         y_tr_pred = clf.predict(X_tr)  # Predict on training data\n",
    "#         y_val_pred = clf.predict(X_val)  # Predict on validation data\n",
    "#\n",
    "#         train_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "#         val_acc = accuracy_score(y_val, y_val_pred)\n",
    "#\n",
    "#         records.append({  # Store results\n",
    "#             \"model\": model_name,\n",
    "#             \"fold\": fold_idx,\n",
    "#             \"train_acc\": train_acc,\n",
    "#             \"val_acc\": val_acc,\n",
    "#         })\n",
    "#\n",
    "# cv_results = pd.DataFrame(records)\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "# Define a helper function to evaluate one model with cross-validation\n",
    "def evaluate_model(X, y, model, model_name, cv):\n",
    "    \"\"\"Run cross-validation for a single model and return results as DataFrame.\"\"\"\n",
    "    # cross_validate runs CV and returns a dictionary of scores\n",
    "    cv_out = cross_validate(\n",
    "        model,  # The model to evaluate\n",
    "        X,  # Features\n",
    "        y,  # Target\n",
    "        cv=cv,  # Cross-validation splitter\n",
    "        scoring=\"accuracy\",  # Metric to compute\n",
    "        return_train_score=True,  # Also compute training scores (for overfitting check)\n",
    "        n_jobs=-1,  # Use all CPU cores for parallelisation\n",
    "    )\n",
    "    # Return results as a DataFrame\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"train_acc\": cv_out[\"train_score\"],  # Training accuracy per fold\n",
    "            \"val_acc\": cv_out[\"test_score\"],  # Validation accuracy per fold\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Create the cross-validation splitter\n",
    "cv = RepeatedStratifiedKFold(\n",
    "    n_splits=NUM_SPLITS,  # Number of folds\n",
    "    n_repeats=NUM_REPEATS,  # Number of times to repeat\n",
    "    random_state=RANDOM_STATE,  # For reproducibility\n",
    ")\n",
    "\n",
    "# Evaluate all models and collect results\n",
    "all_results = []\n",
    "print(\"Starting model evaluations...\")\n",
    "\n",
    "# Loop through each model in our dictionary\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\t{model_name}\")  # Progress indicator\n",
    "    res = evaluate_model(X_train_processed, y_train, model, model_name, cv)\n",
    "    all_results.append(res)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "# pd.concat with ignore_index=True resets the row indices\n",
    "cv_results = pd.concat(all_results, ignore_index=True)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa65bd",
   "metadata": {},
   "source": [
    "### Mean train vs validation accuracy per model\n",
    "\n",
    "We summarise average training and validation accuracy to check for systematic overfitting.\n",
    "A large gap between train and validation accuracy suggests the model memorises training\n",
    "data rather than learning generalisable patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b35fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .groupby(\"model\") groups rows by model name\n",
    "# [[\"train_acc\", \"val_acc\"]] selects just these columns\n",
    "# .median() computes median for each group\n",
    "# .sort_values() sorts by validation accuracy (best model first)\n",
    "median_scores = cv_results.groupby(\"model\")[[\"train_acc\", \"val_acc\"]].median().sort_values(\"val_acc\", ascending=False)\n",
    "median_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b123ff2",
   "metadata": {},
   "source": [
    "If a model has **very high train accuracy** but noticeably lower validation accuracy, it may be **overfitting** (memorising training patterns that do not generalise).\n",
    "\n",
    "Models whose train and validation accuracies are closer together are typically better balanced between bias and variance for this setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a01f6d",
   "metadata": {},
   "source": [
    "## 10. Visualising Accuracy with Violin Plots\n",
    "\n",
    "We now visualise the distribution of **validation accuracy** across folds for each model using violin plots.\n",
    "\n",
    "This reveals not only the mean performance but also variability and potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create violin plot showing accuracy distribution for each model\n",
    "plt.figure(figsize=(8, 9))\n",
    "\n",
    "# sns.violinplot shows the distribution shape, not just summary statistics\n",
    "# inner=\"quartile\" draws lines at the quartiles inside the violin\n",
    "sns.violinplot(data=cv_results, x=\"model\", y=\"val_acc\", inner=\"quartile\", palette=\"Set2\")\n",
    "\n",
    "plt.title(\"Validation accuracy distribution by model (RepeatedStratifiedKFold)\")\n",
    "plt.ylabel(\"Validation accuracy\")\n",
    "\n",
    "# Add a horizontal reference line at the best model's median accuracy\n",
    "# .idxmax() returns the index (model name) with the maximum value\n",
    "plt.axhline(y=median_scores.loc[median_scores[\"val_acc\"].idxmax(), \"val_acc\"], color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylim(0.7, 1.0)  # Set y-axis range\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = os.path.join(out_folder, \"validation_accuracy_distribution_by_model.pdf\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a0731",
   "metadata": {},
   "source": [
    "Remember: **accuracy** can look quite good on an imbalanced dataset even if the minority class is poorly predicted.\n",
    "\n",
    "In Coding Exercise 2 we will revisit these models with more informative metrics (precision, recall, F1, MCC, ROC/PR curves)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a93a08",
   "metadata": {},
   "source": [
    "## 11. Select the Best Model by Mean Validation Accuracy\n",
    "\n",
    "We now select the model with the highest **mean validation accuracy** across CV folds, then:\n",
    "\n",
    "- Fit that model on **all processed training data**.\n",
    "- Evaluate it once on the **held-out test set**.\n",
    "- Visualise the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best model by median validation accuracy\n",
    "# .idxmax() returns the row index (model name) with the highest value\n",
    "best_model_name = median_scores[\"val_acc\"].idxmax()\n",
    "best_model_name, median_scores.loc[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9175bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on FULL processed training data\n",
    "# clone() creates a fresh copy of the model (unfitted)\n",
    "best_model = clone(models[best_model_name])\n",
    "best_model.fit(X_train_processed, y_train)  # Train on all training data\n",
    "\n",
    "# Evaluate on held-out test set (data the model has never seen)\n",
    "y_test_pred = best_model.predict(X_test_processed)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test accuracy of best model ({best_model_name}): {test_acc:.4f}\")\n",
    "\n",
    "# Create and display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lb.classes_)\n",
    "disp.plot(cmap=\"Reds\", values_format=\"d\")  # \"d\" formats as integers\n",
    "\n",
    "ax = plt.gca()  # Get current axes\n",
    "ax.grid(False)  # Turn off grid for cleaner look\n",
    "\n",
    "plt.title(f\"Confusion matrix on held-out test set ({best_model_name})\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = os.path.join(out_folder, \"confusion_matrix_on_held_out_test_set.pdf\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to: {out_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741935a",
   "metadata": {},
   "source": [
    "The confusion matrix shows how many:\n",
    "- True negatives (correct `<=50K`)\n",
    "- True positives (correct `>50K`)\n",
    "- False positives (`<=50K` predicted as `>50K`)\n",
    "- False negatives (`>50K` predicted as `<=50K`)\n",
    "\n",
    "Even if overall accuracy looks good, we should be cautious if one type of error (e.g. false negatives) is particularly frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02acef0",
   "metadata": {},
   "source": [
    "## 12. Wrap-Up and Bridge to Coding Exercise 2\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "- Framed the Adult Census Income prediction task as a **binary classification** problem.\n",
    "- Explored the data: feature types, distributions, class imbalance, and missing values.\n",
    "- Performed **stratified** train/test splitting with a fixed random seed.\n",
    "- Applied **RobustScaler** to numerical features and **one-hot encoding** to categorical features using only the training data (to avoid leakage to test).\n",
    "- Evaluated several scikit-learn models using **RepeatedStratifiedKFold** and **accuracy**.\n",
    "- Checked for overfitting by comparing train vs validation accuracy.\n",
    "- Visualised accuracy distributions with violin plots.\n",
    "- Trained the best model on all training data and inspected its test-set confusion matrix.\n",
    "\n",
    "### Next steps (Coding Exercise 2)\n",
    "\n",
    "In Coding Exercise 2 and the accompanying notebook we will:\n",
    "\n",
    "- See why accuracy can be misleading on imbalanced data.\n",
    "- Introduce metrics like **precision**, **recall**, **F1**, **MCC**, **ROC/PR curves**.\n",
    "- Use **Pipelines** and **ColumnTransformer** to cleanly combine preprocessing and models.\n",
    "- Apply **hyperparameter tuning** (GridSearchCV, RandomizedSearchCV, Optuna) in a way that respects cross-validation and avoids leakage.\n",
    "\n",
    "This will turn today's basic lifecycle into a more robust and production-ready ML workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3.13.5",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
